{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3 : Mitigate Bias, Train another unbiased Model and Put in the Model Registry"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='aup-overview'></a>\n",
    "\n",
    "## [Overview](./0-AutoClaimFraudDetection.ipynb)\n",
    "* [Notebook 0 : Overview, Architecture and Data Exploration](./0-AutoClaimFraudDetection.ipynb)\n",
    "* [Notebook 1: Data Prep, Process, Store Features](./1-data-prep-e2e.ipynb)\n",
    "* [Notebook 2: Train, Check Bias, Tune, Record Lineage, and Register a Model](./2-lineage-train-assess-bias-tune-registry-e2e.ipynb)\n",
    "* **[Notebook 3: Mitigate Bias, Train New Model, Store in Registry](./3-mitigate-bias-train-model2-registry-e2e.ipynb)**\n",
    "  * **[Architecture](#train2)**\n",
    "  * **[Develop a second model](#second-model)**\n",
    "  * **[Analyze the Second Model for Bias](#analyze-second-model)**\n",
    "  * **[View Results of Clarify Bias Detection Job](#view-second-clarify-job)**\n",
    "  * **[Configure and Run Clarify Explainability Job](#explainability)**\n",
    "  * **[Create Model Package for the Second Trained Model](#model-package)**\n",
    "* [Notebook 4: Deploy Model, Run Predictions](./4-deploy-run-inference-e2e.ipynb)\n",
    "* [Notebook 5 : Create and Run an End-to-End Pipeline to Deploy the Model](./5-pipeline-e2e.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 노트북에서는 Clarify를 사용하여 편향을 감지하고, SMOTE를 사용하여 이를 완화하고, 다른 모델을 훈련하고, 그 과정에서 생성된 모든 아티팩트 계보(데이터, 코드 및 모델 메타데이터)와 함께 모델 레지스트리에 배치하는 방법을 설명합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import time\n",
    "import boto3\n",
    "import sagemaker\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import awswrangler as wr\n",
    "import matplotlib.pyplot as plt\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sagemaker.xgboost.estimator import XGBoost\n",
    "\n",
    "from model_package_src.inference_specification import InferenceSpecification\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load stored variables\n",
    "\n",
    "이전에 이 노트북을 실행한 경우, AWS에서 생성한 리소스를 재사용할 수 있습니다. 아래 셀을 실행하여 이전에 생성된 변수를 로드합니다. 기존 변수의 출력물이 표시되어야 합니다. 인쇄된 내용이 보이지 않으면 노트북을 처음 실행한 것일 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r\n",
    "%store"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<font color='red'>Important</font>: StoreMagic 명령을 사용하여 변수를 검색하려면 이전 노트북을 실행해야 합니다.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set region, boto3 and SageMaker SDK variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#You can change this to a region of your choice\n",
    "import sagemaker\n",
    "region = sagemaker.Session().boto_region_name\n",
    "print(\"Using AWS Region: {}\".format(region))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boto3.setup_default_session(region_name=region)\n",
    "\n",
    "boto_session = boto3.Session(region_name=region)\n",
    "\n",
    "s3_client = boto3.client(\"s3\", region_name=region)\n",
    "\n",
    "sagemaker_boto_client = boto_session.client(\"sagemaker\")\n",
    "\n",
    "sagemaker_session = sagemaker.session.Session(\n",
    "    boto_session=boto_session, sagemaker_client=sagemaker_boto_client\n",
    ")\n",
    "\n",
    "sagemaker_role = sagemaker.get_execution_role()\n",
    "\n",
    "account_id = boto3.client(\"sts\").get_caller_identity()[\"Account\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# variables used for parameterizing the notebook run\n",
    "model_2_name = f\"{prefix}-xgboost-post-smote\"\n",
    "\n",
    "train_data_upsampled_s3_path = f\"s3://{bucket}/{prefix}/data/train/upsampled/train.csv\"\n",
    "bias_report_2_output_path = f\"s3://{bucket}/{prefix}/clarify-output/bias-2\"\n",
    "explainability_output_path = f\"s3://{bucket}/{prefix}/clarify-output/explainability\"\n",
    "\n",
    "train_instance_count = 1\n",
    "train_instance_type = \"ml.m4.xlarge\"\n",
    "\n",
    "claify_instance_count = 1\n",
    "clairfy_instance_type = \"ml.c5.xlarge\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id ='train2'> </a>\n",
    "## Architecture for this ML Lifecycle Stage : Train, Check Bias, Tune, Record Lineage, Register Model\n",
    "[overview](#aup-overview)\n",
    "___\n",
    "\n",
    "![train-assess-tune-register](./images/e2e-2-pipeline-v3b.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='second-model'></a>\n",
    "\n",
    "## Develop a second model\n",
    "\n",
    "[overview](#aup-overview)\n",
    "___\n",
    "\n",
    "이 두 번째 모델에서는 SMOTE를 사용하여 데이터셋의 성별 불균형을 수정하고 XGBoost를 사용하여 다른 모델을 훈련합니다. 이 모델은 또한 레지스트리에 저장되고 최종적으로 배포가 승인됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"data/train.csv\")\n",
    "test = pd.read_csv(\"data/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='smote'></a>\n",
    "### Resolve class imbalance using SMOTE\n",
    "\n",
    "불균형을 처리하기 위해 [SMOTE (Synthetic Minority Over-sampling Technique)](https://arxiv.org/pdf/1106.1813.pdf)를 사용하여 소수 클래스를 오버샘플링 (즉, 업샘플링) 할 수 있습니다. imbalanced-learn 모듈을 설치한 후 SMOTE를 임포트할 때 ImportError가 발생하면 커널을 다시 시작하십시오."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gender balance before SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gender = train['customer_gender_female']\n",
    "gender.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gender balance after SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm = SMOTE(random_state=42)\n",
    "train_data_upsampled, gender_res = sm.fit_resample(train, gender)\n",
    "train_data_upsampled['customer_gender_female'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train new model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_upsampled.to_csv(\"data/upsampled_train.csv\", index=False)\n",
    "s3_client.upload_file(\n",
    "    Filename=\"data/upsampled_train.csv\",\n",
    "    Bucket=bucket,\n",
    "    Key=f\"{prefix}/data/train/upsampled/train.csv\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_estimator = XGBoost(\n",
    "    entry_point=\"xgboost_starter_script.py\",\n",
    "    hyperparameters=hyperparameters,\n",
    "    role=sagemaker_role,\n",
    "    instance_count=train_instance_count,\n",
    "    instance_type=train_instance_type,\n",
    "    framework_version=\"1.0-1\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if 'training_job_2_name' not in locals():\n",
    "    \n",
    "    xgb_estimator.fit(inputs = {'train': train_data_upsampled_s3_path})\n",
    "    training_job_2_name = xgb_estimator.latest_training_job.job_name\n",
    "    %store training_job_2_name\n",
    "    \n",
    "else:\n",
    "    \n",
    "    print(f'Using previous training job: {training_job_2_name}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Register artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_job_2_info = sagemaker_boto_client.describe_training_job(\n",
    "    TrainingJobName=training_job_2_name\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code artifact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# return any existing artifact which match the our training job's code arn\n",
    "code_s3_uri = training_job_2_info[\"HyperParameters\"][\"sagemaker_submit_directory\"]\n",
    "\n",
    "list_response = list(\n",
    "    sagemaker.lineage.artifact.Artifact.list(\n",
    "        source_uri=code_s3_uri, sagemaker_session=sagemaker_session\n",
    "    )\n",
    ")\n",
    "\n",
    "# use existing arifact if it's already been created, otherwise create a new artifact\n",
    "if list_response:\n",
    "    code_artifact = list_response[0]\n",
    "    print(f\"Using existing artifact: {code_artifact.artifact_arn}\")\n",
    "else:\n",
    "    code_artifact = sagemaker.lineage.artifact.Artifact.create(\n",
    "        artifact_name=\"TrainingScript\",\n",
    "        source_uri=code_s3_uri,\n",
    "        artifact_type=\"Code\",\n",
    "        sagemaker_session=sagemaker_session,\n",
    "    )\n",
    "    print(f\"Create artifact {code_artifact.artifact_arn}: SUCCESSFUL\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training data artifact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data_s3_uri = training_job_2_info['InputDataConfig'][0]['DataSource']['S3DataSource']['S3Uri']\n",
    "\n",
    "list_response = list(\n",
    "    sagemaker.lineage.artifact.Artifact.list(\n",
    "        source_uri=training_data_s3_uri, sagemaker_session=sagemaker_session\n",
    "    )\n",
    ")\n",
    "\n",
    "if list_response:\n",
    "    training_data_artifact = list_response[0]\n",
    "    print(f\"Using existing artifact: {training_data_artifact.artifact_arn}\")\n",
    "else:\n",
    "    training_data_artifact = sagemaker.lineage.artifact.Artifact.create(\n",
    "        artifact_name=\"TrainingData\",\n",
    "        source_uri=training_data_s3_uri,\n",
    "        artifact_type=\"Dataset\",\n",
    "        sagemaker_session=sagemaker_session,\n",
    "    )\n",
    "    print(f\"Create artifact {training_data_artifact.artifact_arn}: SUCCESSFUL\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model artifact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_model_s3_uri = training_job_2_info[\"ModelArtifacts\"][\"S3ModelArtifacts\"]\n",
    "\n",
    "list_response = list(\n",
    "    sagemaker.lineage.artifact.Artifact.list(\n",
    "        source_uri=trained_model_s3_uri, sagemaker_session=sagemaker_session\n",
    "    )\n",
    ")\n",
    "\n",
    "if list_response:\n",
    "    model_artifact = list_response[0]\n",
    "    print(f\"Using existing artifact: {model_artifact.artifact_arn}\")\n",
    "else:\n",
    "    model_artifact = sagemaker.lineage.artifact.Artifact.create(\n",
    "        artifact_name=\"TrainedModel\",\n",
    "        source_uri=trained_model_s3_uri,\n",
    "        artifact_type=\"Model\",\n",
    "        sagemaker_session=sagemaker_session,\n",
    "    )\n",
    "    print(f\"Create artifact {model_artifact.artifact_arn}: SUCCESSFUL\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set artifact associations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_component = sagemaker_boto_client.describe_trial_component(\n",
    "    TrialComponentName=training_job_2_name + \"-aws-training-job\"\n",
    ")\n",
    "trial_component_arn = trial_component[\"TrialComponentArn\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Input artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_artifacts = [code_artifact, training_data_artifact]\n",
    "\n",
    "for a in input_artifacts:\n",
    "    try:\n",
    "        sagemaker.lineage.association.Association.create(\n",
    "            source_arn=a.artifact_arn,\n",
    "            destination_arn=trial_component_arn,\n",
    "            association_type=\"ContributedTo\",\n",
    "            sagemaker_session=sagemaker_session,\n",
    "        )\n",
    "        print(f\"Associate {trial_component_arn} and {a.artifact_arn}: SUCCEESFUL\\n\")\n",
    "    except:\n",
    "        print(f\"Association already exists between {trial_component_arn} and {a.artifact_arn}.\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Output artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_artifacts = [model_artifact]\n",
    "\n",
    "for artifact_arn in output_artifacts:\n",
    "    try:\n",
    "        sagemaker.lineage.association.Association.create(\n",
    "            source_arn=a.artifact_arn,\n",
    "            destination_arn=trial_component_arn,\n",
    "            association_type=\"Produced\",\n",
    "            sagemaker_session=sagemaker_session,\n",
    "        )\n",
    "        print(f\"Associate {trial_component_arn} and {a.artifact_arn}: SUCCEESFUL\\n\")\n",
    "    except:\n",
    "        print(f\"Association already exists between {trial_component_arn} and {a.artifact_arn}.\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<pre>\n",
    "\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id ='analyze-second-model'></a>\n",
    "## Analyze the second model for bias and explainability\n",
    "\n",
    "[overview](#aup-overview)\n",
    "___\n",
    "Amazon SageMaker Clarify는 머신 러닝 (ML) 모델이 예측을 수행하는 방법을 설명하는 데 도움이 되는 도구를 제공합니다. 이러한 도구는 ML 모델러와 개발자 및 기타 내부 이해 관계자가 배포 전에 모델 특성을 전체적으로 이해하고 배포 후 모델에서 제공하는 예측을 디버그하는 데 도움이 될 수 있습니다. ML 모델이 예측에 어떻게 도달하는지에 대한 투명성은 모델 예측을 기반으로 결정을 받아들일 경우, 이를 신뢰해야 하는 소비자 및 규제 기관에게도 중요합니다. SageMaker Clarify는 모델에 구애받지 않는(model-agnostic) 피쳐 속성 접근 방식을 사용합니다. 모델 훈련 후 예측을 수행 한 이유를 이해하고 추론 중에 인스턴스 별 설명을 제공하는 데 사용할 수 있습니다. 구현에는 각 피쳐에 특정 예측에 대한 중요도 값을 할당하는 협동 게임 이론 분야의 Shapley 값 개념을 기반으로 확장 가능하고(scalable) 효율적인 SHAP 구현([see paper](https://papers.nips.cc/paper/2017/file/8a20a8621978632d76c43dfd28b67767-Paper.pdf)이 포함됩니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create model from estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_matches = sagemaker_boto_client.list_models(NameContains=model_2_name)['Models']\n",
    "\n",
    "if not model_matches:\n",
    "    \n",
    "    model_2 = sagemaker_session.create_model_from_job(\n",
    "        name=model_2_name,\n",
    "        training_job_name=training_job_2_info['TrainingJobName'],\n",
    "        role=sagemaker_role,\n",
    "        image_uri=training_job_2_info['AlgorithmSpecification']['TrainingImage'])\n",
    "    %store model_2_name\n",
    "    \n",
    "else:\n",
    "    \n",
    "    print(f\"Model {model_2_name} already exists.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='bias-v1'></a>\n",
    "### Check for data set bias and model bias\n",
    "\n",
    "SageMaker를 사용하면 사전 훈련 및 사후 훈련 편향을 확인할 수 있습니다. 사전 훈련 metric은 해당 데이터의 기존 metric을 보여주는 반면, 사후 훈련 metric은 모델의 예측에서 편향을 보여줍니다. SageMaker SDK를 사용하여 편향을 확인하려는 그룹과 표시할 metric을 지정할 수 있습니다.\n",
    "\n",
    "전체 Clarify 작업을 실행하려면, 아래 셀에서 코드의 주석 처리를 제거해야 합니다. 작업을 실행하는 데 약 15분 정도 소요됩니다. 시간을 절약하려면 편향 작업이 실행되지 않은 경우 미리 생성된 결과를 로드한 후, 다음 셀에서 결과를 볼 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clarify_processor = sagemaker.clarify.SageMakerClarifyProcessor(\n",
    "    role=sagemaker_role,\n",
    "    instance_count=1,\n",
    "    instance_type=\"ml.c4.xlarge\",\n",
    "    sagemaker_session=sagemaker_session,\n",
    ")\n",
    "\n",
    "bias_data_config = sagemaker.clarify.DataConfig(\n",
    "    s3_data_input_path=train_data_upsampled_s3_path,\n",
    "    s3_output_path=bias_report_2_output_path,\n",
    "    label=\"fraud\",\n",
    "    headers=train.columns.to_list(),\n",
    "    dataset_type=\"text/csv\",\n",
    ")\n",
    "\n",
    "model_config = sagemaker.clarify.ModelConfig(\n",
    "    model_name=model_2_name,\n",
    "    instance_type=train_instance_type,\n",
    "    instance_count=1,\n",
    "    accept_type=\"text/csv\",\n",
    ")\n",
    "\n",
    "predictions_config = sagemaker.clarify.ModelPredictedLabelConfig(probability_threshold=0.5)\n",
    "\n",
    "bias_config = sagemaker.clarify.BiasConfig(\n",
    "    label_values_or_threshold=[0],\n",
    "    facet_name=\"customer_gender_female\",\n",
    "    facet_values_or_threshold=[1],\n",
    ")\n",
    "\n",
    "# # un-comment the code below to run the whole job\n",
    "\n",
    "# if 'clarify_bias_job_2_name' not in locals():\n",
    "\n",
    "#     clarify_processor.run_bias(\n",
    "#         data_config=bias_data_config,\n",
    "#         bias_config=bias_config,\n",
    "#         model_config=model_config,\n",
    "#         model_predicted_label_config=predictions_config,\n",
    "#         pre_training_methods='all',\n",
    "#         post_training_methods='all')\n",
    "\n",
    "#     clarify_bias_job_2_name = clarify_processor.latest_job.name\n",
    "#     %store clarify_bias_job_2_name\n",
    "\n",
    "# else:\n",
    "#     print(f'Clarify job {clarify_bias_job_2_name} has already run successfully.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id ='view-second-clarify-job'></a>\n",
    "## View results of Clarify job\n",
    "[overview](#aup-overview)\n",
    "___\n",
    "\n",
    "데이터셋 또는 모델에서 Clarify를 실행하는 데 15분 정도 걸릴 수 있습니다. 작업을 실행할 시간이 없는 경우, 이 데모에 포함된 미리 생성된 결과를 볼 수 있습니다. 그렇지 않으면 위의 셀에서 코드 주석 처리를 제거하여 작업을 실행할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"clarify_bias_job_2_name\" in locals():\n",
    "    s3_client.download_file(\n",
    "        Bucket=bucket,\n",
    "        Key=f\"{prefix}/clarify-output/bias-2/analysis.json\",\n",
    "        Filename=\"clarify_output/bias_2/analysis.json\",\n",
    "    )\n",
    "    print(f\"Downloaded analysis from previous Clarify job: {clarify_bias_job_2_name}\\n\")\n",
    "else:\n",
    "    print(f\"Loading pre-generated analysis file...\\n\")\n",
    "\n",
    "with open(\"clarify_output/bias_1/analysis.json\", \"r\") as f:\n",
    "    bias_analysis = json.load(f)\n",
    "\n",
    "results = bias_analysis[\"pre_training_bias_metrics\"][\"facets\"][\"customer_gender_female\"][0][\n",
    "    \"metrics\"\n",
    "][1]\n",
    "print(json.dumps(results, indent=4))\n",
    "\n",
    "with open(\"clarify_output/bias_2/analysis.json\", \"r\") as f:\n",
    "    bias_analysis = json.load(f)\n",
    "\n",
    "results = bias_analysis[\"pre_training_bias_metrics\"][\"facets\"][\"customer_gender_female\"][0][\n",
    "    \"metrics\"\n",
    "][1]\n",
    "print(json.dumps(results, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id ='explainability' ></a>\n",
    "## Configure and run explainability job\n",
    "[overview](#aup-overview)\n",
    "___\n",
    "전체 Clarify 작업을 실행하려면, 아래 셀에서 코드의 주석 처리를 제거해야 합니다. 작업을 실행하는 데 약 15분 정도 소요됩니다. 시간을 절약하려면 편향 작업이 실행되지 않은 경우 미리 생성된 결과를 로드한 후, 다음 셀에서 결과를 볼 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_config = sagemaker.clarify.ModelConfig(\n",
    "    model_name=model_2_name,\n",
    "    instance_type=train_instance_type,\n",
    "    instance_count=1,\n",
    "    accept_type=\"text/csv\",\n",
    ")\n",
    "\n",
    "shap_config = sagemaker.clarify.SHAPConfig(\n",
    "    baseline=[train.median().values[1:].tolist()], num_samples=100, agg_method=\"mean_abs\"\n",
    ")\n",
    "\n",
    "explainability_data_config = sagemaker.clarify.DataConfig(\n",
    "    s3_data_input_path=train_data_upsampled_s3_path,\n",
    "    s3_output_path=explainability_output_path,\n",
    "    label=\"fraud\",\n",
    "    headers=train.columns.to_list(),\n",
    "    dataset_type=\"text/csv\",\n",
    ")\n",
    "\n",
    "# un-comment the code below to run the whole job\n",
    "\n",
    "# if 'clarify_expl_job_name' not in locals():\n",
    "\n",
    "#     clarify_processor.run_explainability(\n",
    "#         data_config=explainability_data_config,\n",
    "#         model_config=model_config,\n",
    "#         explainability_config=shap_config)\n",
    "\n",
    "#     clarify_expl_job_name = clarify_processor.latest_job.name\n",
    "#     %store clarify_expl_job_name\n",
    "\n",
    "# else:\n",
    "#     print(f'Clarify job {clarify_expl_job_name} has already run successfully.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View Clarify explainability results (shortcut)\n",
    "데이터셋 또는 모델에서 Clarify를 실행하는 데 15분 정도 걸릴 수 있습니다. 작업을 실행할 시간이 없는 경우, 이 데모에 포함된 미리 생성된 결과를 볼 수 있습니다. 그렇지 않으면 위의 셀에서 코드 주석 처리를 제거하여 작업을 실행할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"clarify_expl_job_name\" in locals():\n",
    "    s3_client.download_file(\n",
    "        Bucket=bucket,\n",
    "        Key=f\"{prefix}/clarify-output/explainability/analysis.json\",\n",
    "        Filename=\"clarify_output/explainability/analysis.json\",\n",
    "    )\n",
    "    print(f\"Downloaded analysis from previous Clarify job: {clarify_expl_job_name}\\n\")\n",
    "else:\n",
    "    print(f\"Loading pre-generated analysis file...\\n\")\n",
    "\n",
    "with open(\"clarify_output/explainability/analysis.json\", \"r\") as f:\n",
    "    analysis_result = json.load(f)\n",
    "\n",
    "shap_values = pd.DataFrame(analysis_result[\"explanations\"][\"kernel_shap\"][\"label0\"])\n",
    "importances = shap_values[\"global_shap_values\"].sort_values(ascending=False)\n",
    "fig, ax = plt.subplots()\n",
    "n = 5\n",
    "y_pos = np.arange(n)\n",
    "importance_scores = importances.values[:n]\n",
    "y_label = importances.index[:n]\n",
    "ax.barh(y_pos, importance_scores, align=\"center\")\n",
    "ax.set_yticks(y_pos)\n",
    "ax.set_yticklabels(y_label)\n",
    "ax.invert_yaxis()\n",
    "ax.set_xlabel(\"SHAP Value (impact on model output)\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "자동 생성된 SageMaker Clarify 보고서를 보려면, 다음 코드를 실행하고 출력 링크를 사용하여 보고서를 엽니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import FileLink, FileLinks\n",
    "\n",
    "display(\n",
    "    \"Click link below to view the SageMaker Clarify report\", FileLink(\"clarify_output/report.pdf\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is SHAP?\n",
    "\n",
    "SHAP은 이 솔루션에서 설명을 계산하는 데 사용되는 방법입니다. 단일 feature\n",
    "permutation과 같은 다른 feature attribution 방법과 달리 SHAP는 가능한 모든 피쳐 조합을 조사하여 단일 피쳐의 효과를 분리하려고 합니다.\n",
    "\n",
    "[SHAP](https://github.com/slundberg/shap) (Lundberg et al. 2017)는 SHapley Additive exPlanations를 나타냅니다. 'Shapley'는 설명을 만드는 데 사용되는 [Shapley\n",
    "values](https://en.wikipedia.org/wiki/Shapley_value)라는 게임 이론 개념과 관련이 있습니다. Shapley 값은 가능한 모든 '연합'을 고려할 때 각 '플레이어'의 한계 기여도를 나타냅니다. 머신 러닝 컨텍스트에서 이를 사용하여 Shapley 값은 가능한 모든 피쳐 셋을 고려할 때 각 피쳐의 한계 기여도를 설명합니다. 'Additive'는 이러한 Shapley 값을 합하여 최종 모델 예측을 제공할 수 있다는 사실과 관련이 있습니다.\n",
    "\n",
    "예를 들어 기본 신용 불이행(credit default risk) 위험도 10%로 시작할 수 있습니다. 피쳐 집합이 주어지면, 각 피쳐에 대한 Shapley 값을 계산할 수 있습니다. 모든 Shapley 값을 합하면 +30%의 누적 값을 얻을 수 있습니다. 따라서 동일한 피쳐 세트가 주어지면 모델이 신용 불이행 위험 도 40% (즉, 10% + 30%)를 반환할 것으로 예상합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='model-package' ></a>\n",
    "## Create Model Package for the Second Trained Model\n",
    "[overview](#aup-overview)\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create and upload second model metrics report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_metrics_report = {\"binary_classification_metrics\": {}}\n",
    "for metric in training_job_2_info[\"FinalMetricDataList\"]:\n",
    "    stat = {metric[\"MetricName\"]: {\"value\": metric[\"Value\"], \"standard_deviation\": \"NaN\"}}\n",
    "    model_metrics_report[\"binary_classification_metrics\"].update(stat)\n",
    "\n",
    "with open(\"training_metrics.json\", \"w\") as f:\n",
    "    json.dump(model_metrics_report, f)\n",
    "\n",
    "metrics_s3_key = (\n",
    "    f\"{prefix}/training_jobs/{training_job_2_info['TrainingJobName']}/training_metrics.json\"\n",
    ")\n",
    "s3_client.upload_file(Filename=\"training_metrics.json\", Bucket=bucket, Key=metrics_s3_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define inference specification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_inference_spec = InferenceSpecification().get_inference_specification_dict(\n",
    "    ecr_image=training_job_2_info[\"AlgorithmSpecification\"][\"TrainingImage\"],\n",
    "    supports_gpu=False,\n",
    "    supported_content_types=[\"text/csv\"],\n",
    "    supported_mime_types=[\"text/csv\"],\n",
    ")\n",
    "\n",
    "mp_inference_spec[\"InferenceSpecification\"][\"Containers\"][0][\"ModelDataUrl\"] = training_job_2_info[\n",
    "    \"ModelArtifacts\"\n",
    "][\"S3ModelArtifacts\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define model metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_metrics = {\n",
    "    \"ModelQuality\": {\n",
    "        \"Statistics\": {\n",
    "            \"ContentType\": \"application/json\",\n",
    "            \"S3Uri\": f\"s3://{bucket}/{metrics_s3_key}\",\n",
    "        }\n",
    "    },\n",
    "    \"Bias\": {\n",
    "        \"Report\": {\n",
    "            \"ContentType\": \"application/json\",\n",
    "            \"S3Uri\": f\"{explainability_output_path}/analysis.json\",\n",
    "        }\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Register second model package to Model Package Group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_input_dict = {\n",
    "    \"ModelPackageGroupName\": mpg_name,\n",
    "    \"ModelPackageDescription\": \"XGBoost classifier to detect insurance fraud with SMOTE.\",\n",
    "    \"ModelApprovalStatus\": \"PendingManualApproval\",\n",
    "    \"ModelMetrics\": model_metrics,\n",
    "}\n",
    "\n",
    "mp_input_dict.update(mp_inference_spec)\n",
    "mp2_response = sagemaker_boto_client.create_model_package(**mp_input_dict)\n",
    "mp2_arn = mp2_response[\"ModelPackageArn\"]\n",
    "%store mp2_arn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check status of model package creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_info = sagemaker_boto_client.describe_model_package(\n",
    "    ModelPackageName=mp2_response[\"ModelPackageArn\"]\n",
    ")\n",
    "mp_status = mp_info[\"ModelPackageStatus\"]\n",
    "\n",
    "while mp_status not in [\"Completed\", \"Failed\"]:\n",
    "    time.sleep(5)\n",
    "    mp_info = sagemaker_boto_client.describe_model_package(\n",
    "        ModelPackageName=mp2_response[\"ModelPackageArn\"]\n",
    "    )\n",
    "    mp_status = mp_info[\"ModelPackageStatus\"]\n",
    "    print(f\"model package status: {mp_status}\")\n",
    "print(f\"model package status: {mp_status}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View both models in the registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sagemaker_boto_client.list_model_packages(ModelPackageGroupName=mpg_name)[\"ModelPackageSummaryList\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "### Next Notebook: [Deploy Model, Run Predictions](./4-deploy-run-inference-e2e.ipynb)"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:ap-northeast-2:806072073708:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
