{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 4 : Deploy, Run Inference, Interpret Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='overview-4'></a>\n",
    "\n",
    "## [Overview](./0-AutoClaimFraudDetection.ipynb)\n",
    "* [Notebook 0 : Overview, Architecture and Data Exploration](./0-AutoClaimFraudDetection.ipynb)\n",
    "* [Notebook 1: Data Prep, Process, Store Features](./1-data-prep-e2e.ipynb)\n",
    "* [Notebook 2: Train, Check Bias, Tune, Record Lineage, and Register a Model](./2-lineage-train-assess-bias-tune-registry-e2e.ipynb)\n",
    "* [Notebook 3: Mitigate Bias, Train New Model, Store in Registry](./3-mitigate-bias-train-model2-registry-e2e.ipynb)\n",
    "* **[Notebook 4: Deploy Model, Run Predictions](./4-deploy-run-inference-e2e.ipynb)**\n",
    "  * **[Architecture](#deploy)**\n",
    "  * **[Deploy an approved model and Run Inference via Feature Store](#deploy-model)**\n",
    "  * **[Create a Predictor](#predictor)**\n",
    "  * **[Run Predictions from Online FeatureStore](#run-predictions)**\n",
    "* [Notebook 5 : Create and Run an End-to-End Pipeline to Deploy the Model](./5-pipeline-e2e.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "End-to-end 유즈케이스를 다루는 이 섹션에서는, 사기 탐지 사용 사례의 최종 프로덕션인 mmitigated 모델을 배포합니다. 추론을 실행하는 방법과 Clarify를 사용하여 모델을 해석하거나 \"설명\"하는 방법을 보여줍니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load stored variables\n",
    "\n",
    "이전에 이 노트북을 실행한 경우, AWS에서 생성한 리소스를 재사용할 수 있습니다. 아래 셀을 실행하여 이전에 생성된 변수를 로드합니다. 기존 변수의 출력물이 표시되어야 합니다. 인쇄된 내용이 보이지 않으면 노트북을 처음 실행한 것일 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored variables and their in-db values:\n",
      "bucket                              -> 'sagemaker-us-east-2-143656149352'\n",
      "claims_fg_name                      -> 'fraud-detect-demo-claims'\n",
      "claims_table                        -> 'fraud-detect-demo-claims-1629447691'\n",
      "clarify_bias_job_1_name             -> 'Clarify-Bias-2021-08-20-08-46-43-569'\n",
      "col_order                           -> ['fraud', 'customer_gender_female', 'customer_gend\n",
      "customers_fg_name                   -> 'fraud-detect-demo-customers'\n",
      "customers_table                     -> 'fraud-detect-demo-customers-1629447692'\n",
      "database_name                       -> 'sagemaker_featurestore'\n",
      "hyperparameters                     -> {'max_depth': '3', 'eta': '0.2', 'objective': 'bin\n",
      "model_1_name                        -> 'fraud-detect-demo-xgboost-pre-smote'\n",
      "model_2_name                        -> 'fraud-detect-demo-xgboost-post-smote'\n",
      "mp2_arn                             -> 'arn:aws:sagemaker:us-east-2:143656149352:model-pa\n",
      "mpg_name                            -> 'fraud-detect-demo'\n",
      "prefix                              -> 'fraud-detect-demo'\n",
      "test_data_uri                       -> 's3://sagemaker-us-east-2-143656149352/fraud-detec\n",
      "train_data_uri                      -> 's3://sagemaker-us-east-2-143656149352/fraud-detec\n",
      "training_job_1_name                 -> 'sagemaker-xgboost-2021-08-20-08-36-37-120'\n",
      "training_job_2_name                 -> 'sagemaker-xgboost-2021-08-20-09-11-10-641'\n"
     ]
    }
   ],
   "source": [
    "%store -r\n",
    "%store"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<font color='red'>Important</font>: StoreMagic 명령을 사용하여 변수를 검색하려면 이전 노트북을 실행해야 합니다.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import time\n",
    "import boto3\n",
    "import sagemaker\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import awswrangler as wr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set region, boto3 and SageMaker SDK variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using AWS Region: us-east-2\n"
     ]
    }
   ],
   "source": [
    "#You can change this to a region of your choice\n",
    "import sagemaker\n",
    "region = sagemaker.Session().boto_region_name\n",
    "print(\"Using AWS Region: {}\".format(region))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "boto3.setup_default_session(region_name=region)\n",
    "\n",
    "boto_session = boto3.Session(region_name=region)\n",
    "\n",
    "s3_client = boto3.client('s3', region_name=region)\n",
    "\n",
    "sagemaker_boto_client = boto_session.client('sagemaker')\n",
    "\n",
    "sagemaker_session = sagemaker.session.Session(\n",
    "    boto_session=boto_session,\n",
    "    sagemaker_client=sagemaker_boto_client)\n",
    "\n",
    "sagemaker_role = sagemaker.get_execution_role()\n",
    "\n",
    "account_id = boto3.client('sts').get_caller_identity()[\"Account\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# variables used for parameterizing the notebook run\n",
    "endpoint_name = f\"{model_2_name}-endpoint\"\n",
    "endpoint_instance_count = 1\n",
    "endpoint_instance_type = \"ml.m4.xlarge\"\n",
    "\n",
    "predictor_instance_count = 1\n",
    "predictor_instance_type = \"ml.c5.xlarge\"\n",
    "batch_transform_instance_count = 1\n",
    "batch_transform_instance_type = \"ml.c5.xlarge\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id ='deploy'> </a>\n",
    "## Architecture for this ML Lifecycle Stage : Train, Check Bias, Tune, Record Lineage, Register Model\n",
    "[overview](#overview-4)\n",
    "\n",
    "![train-assess-tune-register](./images/e2e-3-pipeline-v3b.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id ='deploy-model'></a>\n",
    "\n",
    "## Deploy an approved model and make prediction via Feature Store\n",
    "\n",
    "[overview](#overview-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Approve the second model\n",
    "\n",
    "실제 MLOps 라이프사이클에서 모델 패키지는 데이터 과학자, 주제 전문가 및 감사자가 평가한 후 승인됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "second_model_package = sagemaker_boto_client.list_model_packages(ModelPackageGroupName=mpg_name)[\n",
    "    \"ModelPackageSummaryList\"\n",
    "][0]\n",
    "model_package_update = {\n",
    "    \"ModelPackageArn\": second_model_package[\"ModelPackageArn\"],\n",
    "    \"ModelApprovalStatus\": \"Approved\",\n",
    "}\n",
    "\n",
    "update_response = sagemaker_boto_client.update_model_package(**model_package_update)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create an endpoint config and an endpoint\n",
    "엔드포인트를 배포합니다. 약 8분 정도 걸릴 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'endpoint_config_name' (str)\n"
     ]
    }
   ],
   "source": [
    "primary_container = {'ModelPackageName': second_model_package['ModelPackageArn']}\n",
    "endpoint_config_name=f'{model_2_name}-endpoint-config'\n",
    "existing_configs = len(sagemaker_boto_client.list_endpoint_configs(NameContains=endpoint_config_name, MaxResults = 30)['EndpointConfigs'])\n",
    "\n",
    "if existing_configs == 0:\n",
    "    create_ep_config_response = sagemaker_boto_client.create_endpoint_config(\n",
    "        EndpointConfigName=endpoint_config_name,\n",
    "        ProductionVariants=[{\n",
    "            'InstanceType': endpoint_instance_type,\n",
    "            'InitialVariantWeight': 1,\n",
    "            'InitialInstanceCount': endpoint_instance_count,\n",
    "            'ModelName': model_2_name,\n",
    "            'VariantName': 'AllTraffic'\n",
    "        }]\n",
    "    )\n",
    "    %store endpoint_config_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'endpoint_name' (str)\n",
      "Endpoint status: Creating\n",
      "Endpoint status: Creating\n",
      "Endpoint status: Creating\n",
      "Endpoint status: Creating\n",
      "Endpoint status: Creating\n",
      "Endpoint status: Creating\n",
      "Endpoint status: Creating\n",
      "Endpoint status: InService\n"
     ]
    }
   ],
   "source": [
    "existing_endpoints = sagemaker_boto_client.list_endpoints(NameContains=endpoint_name, MaxResults = 30)['Endpoints']\n",
    "if not existing_endpoints:\n",
    "    create_endpoint_response = sagemaker_boto_client.create_endpoint(\n",
    "        EndpointName=endpoint_name,\n",
    "        EndpointConfigName=endpoint_config_name)\n",
    "    %store endpoint_name\n",
    "\n",
    "endpoint_info = sagemaker_boto_client.describe_endpoint(EndpointName=endpoint_name)\n",
    "endpoint_status = endpoint_info['EndpointStatus']\n",
    "\n",
    "while endpoint_status == 'Creating':\n",
    "    endpoint_info = sagemaker_boto_client.describe_endpoint(EndpointName=endpoint_name)\n",
    "    endpoint_status = endpoint_info['EndpointStatus']\n",
    "    print('Endpoint status:', endpoint_status)\n",
    "    if endpoint_status == 'Creating':\n",
    "        time.sleep(60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='predictor'> </a>\n",
    "\n",
    "### Create a predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = sagemaker.predictor.Predictor(\n",
    "    endpoint_name=endpoint_name, sagemaker_session=sagemaker_session\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample a claim from the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"data/dataset.csv\")\n",
    "train = dataset.sample(frac=0.8, random_state=0)\n",
    "test = dataset.drop(train.index)\n",
    "sample_policy_id = int(test.sample(1)[\"policy_id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1000 entries, 0 to 4997\n",
      "Data columns (total 48 columns):\n",
      " #   Column                           Non-Null Count  Dtype  \n",
      "---  ------                           --------------  -----  \n",
      " 0   Unnamed: 0                       1000 non-null   int64  \n",
      " 1   policy_id                        1000 non-null   int64  \n",
      " 2   customer_gender_female           1000 non-null   int64  \n",
      " 3   customer_gender_male             1000 non-null   int64  \n",
      " 4   policy_state_or                  1000 non-null   int64  \n",
      " 5   injury_claim                     1000 non-null   float64\n",
      " 6   policy_state_ca                  1000 non-null   int64  \n",
      " 7   collision_type_na                1000 non-null   int64  \n",
      " 8   police_report_available          1000 non-null   int64  \n",
      " 9   incident_month                   1000 non-null   int64  \n",
      " 10  policy_state_nv                  1000 non-null   int64  \n",
      " 11  customer_age                     1000 non-null   int64  \n",
      " 12  collision_type_front             1000 non-null   int64  \n",
      " 13  total_claim_amount               1000 non-null   float64\n",
      " 14  incident_type_theft              1000 non-null   int64  \n",
      " 15  collision_type_side              1000 non-null   int64  \n",
      " 16  customer_education               1000 non-null   int64  \n",
      " 17  policy_state_wa                  1000 non-null   int64  \n",
      " 18  incident_type_breakin            1000 non-null   int64  \n",
      " 19  num_witnesses                    1000 non-null   int64  \n",
      " 20  driver_relationship_child        1000 non-null   int64  \n",
      " 21  auto_year                        1000 non-null   int64  \n",
      " 22  authorities_contacted_fire       1000 non-null   int64  \n",
      " 23  policy_annual_premium            1000 non-null   int64  \n",
      " 24  driver_relationship_spouse       1000 non-null   int64  \n",
      " 25  collision_type_rear              1000 non-null   int64  \n",
      " 26  months_as_customer               1000 non-null   int64  \n",
      " 27  num_injuries                     1000 non-null   int64  \n",
      " 28  num_insurers_past_5_years        1000 non-null   int64  \n",
      " 29  incident_dow                     1000 non-null   int64  \n",
      " 30  driver_relationship_na           1000 non-null   int64  \n",
      " 31  incident_day                     1000 non-null   int64  \n",
      " 32  authorities_contacted_none       1000 non-null   int64  \n",
      " 33  policy_state_az                  1000 non-null   int64  \n",
      " 34  num_claims_past_year             1000 non-null   int64  \n",
      " 35  policy_state_id                  1000 non-null   int64  \n",
      " 36  num_vehicles_involved            1000 non-null   int64  \n",
      " 37  incident_severity                1000 non-null   int64  \n",
      " 38  policy_deductable                1000 non-null   int64  \n",
      " 39  authorities_contacted_police     1000 non-null   int64  \n",
      " 40  incident_type_collision          1000 non-null   int64  \n",
      " 41  fraud                            1000 non-null   int64  \n",
      " 42  authorities_contacted_ambulance  1000 non-null   int64  \n",
      " 43  driver_relationship_other        1000 non-null   int64  \n",
      " 44  policy_liability                 1000 non-null   int64  \n",
      " 45  incident_hour                    1000 non-null   int64  \n",
      " 46  driver_relationship_self         1000 non-null   int64  \n",
      " 47  vehicle_claim                    1000 non-null   float64\n",
      "dtypes: float64(3), int64(45)\n",
      "memory usage: 382.8 KB\n"
     ]
    }
   ],
   "source": [
    "test.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get sample's claim data from online feature store\n",
    "\n",
    "아래 코드 셀은 고객의 보험 청구 제출에서 실시간으로 데이터를 가져 오는 것을 시뮬레이션합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "featurestore_runtime = boto_session.client(\n",
    "    service_name=\"sagemaker-featurestore-runtime\", region_name=region\n",
    ")\n",
    "\n",
    "feature_store_session = sagemaker.Session(\n",
    "    boto_session=boto_session,\n",
    "    sagemaker_client=sagemaker_boto_client,\n",
    "    sagemaker_featurestore_runtime_client=featurestore_runtime,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='run-predictions'> </a>\n",
    "## Run Predictions on Multiple Claims\n",
    "\n",
    "[overview](#overview-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probablitity the claim from policy 4275 is fraudulent: 0.004453680943697691\n",
      "Probablitity the claim from policy 6 is fraudulent: 0.0025477695744484663\n",
      "Probablitity the claim from policy 4203 is fraudulent: 0.0060280426405370235\n",
      "Probablitity the claim from policy 3032 is fraudulent: 0.025583526119589806\n",
      "Probablitity the claim from policy 3322 is fraudulent: 0.005415594670921564\n",
      "Probablitity the claim from policy 435 is fraudulent: 0.008797605521976948\n",
      "Probablitity the claim from policy 4280 is fraudulent: 0.008219864219427109\n",
      "Probablitity the claim from policy 3598 is fraudulent: 0.0020912406034767628\n",
      "Probablitity the claim from policy 2060 is fraudulent: 0.0026974573265761137\n",
      "Probablitity the claim from policy 2445 is fraudulent: 0.03141326084733009\n",
      "Probablitity the claim from policy 1580 is fraudulent: 0.018626952543854713\n",
      "Probablitity the claim from policy 2570 is fraudulent: 0.012887710705399513\n",
      "Probablitity the claim from policy 1571 is fraudulent: 0.009747525677084923\n",
      "Probablitity the claim from policy 4283 is fraudulent: 0.003183591179549694\n",
      "Probablitity the claim from policy 2598 is fraudulent: 0.014740374870598316\n",
      "Probablitity the claim from policy 2957 is fraudulent: 0.042442020028829575\n",
      "Probablitity the claim from policy 972 is fraudulent: 0.14078453183174133\n",
      "Probablitity the claim from policy 3988 is fraudulent: 0.003103837138041854\n",
      "Probablitity the claim from policy 1446 is fraudulent: 0.03216509893536568\n",
      "Probablitity the claim from policy 3855 is fraudulent: 0.002176637062802911\n",
      "Probablitity the claim from policy 1473 is fraudulent: 0.006835799664258957\n",
      "Probablitity the claim from policy 4171 is fraudulent: 0.0038955032359808683\n",
      "Probablitity the claim from policy 4459 is fraudulent: 0.005251699592918158\n",
      "Probablitity the claim from policy 3775 is fraudulent: 0.03240674361586571\n",
      "Probablitity the claim from policy 4669 is fraudulent: 0.060381099581718445\n",
      "Probablitity the claim from policy 3177 is fraudulent: 0.0075848218984901905\n",
      "Probablitity the claim from policy 2535 is fraudulent: 0.002113141817972064\n",
      "Probablitity the claim from policy 2683 is fraudulent: 0.013547363691031933\n",
      "Probablitity the claim from policy 2621 is fraudulent: 0.007308539003133774\n",
      "Probablitity the claim from policy 1449 is fraudulent: 0.048954371362924576\n",
      "Probablitity the claim from policy 2912 is fraudulent: 0.0017475535860285163\n",
      "Probablitity the claim from policy 3453 is fraudulent: 0.030093224719166756\n",
      "Probablitity the claim from policy 1694 is fraudulent: 0.003943080082535744\n",
      "Probablitity the claim from policy 954 is fraudulent: 0.019287601113319397\n",
      "Probablitity the claim from policy 2388 is fraudulent: 0.0025063655339181423\n",
      "Probablitity the claim from policy 429 is fraudulent: 0.03141326084733009\n",
      "Probablitity the claim from policy 2084 is fraudulent: 0.0272782351821661\n",
      "Probablitity the claim from policy 2018 is fraudulent: 0.016077058389782906\n",
      "Probablitity the claim from policy 1962 is fraudulent: 0.007076692767441273\n",
      "Probablitity the claim from policy 4156 is fraudulent: 0.0294471625238657\n",
      "Probablitity the claim from policy 1750 is fraudulent: 0.015883805230259895\n",
      "Probablitity the claim from policy 2231 is fraudulent: 0.021298633888363838\n",
      "Probablitity the claim from policy 4879 is fraudulent: 0.0030327041167765856\n",
      "Probablitity the claim from policy 3156 is fraudulent: 0.008326106704771519\n",
      "Probablitity the claim from policy 866 is fraudulent: 0.003371188184246421\n",
      "Probablitity the claim from policy 1596 is fraudulent: 0.008462915197014809\n",
      "Probablitity the claim from policy 3949 is fraudulent: 0.011844276450574398\n",
      "Probablitity the claim from policy 3919 is fraudulent: 0.004885748960077763\n",
      "Probablitity the claim from policy 2651 is fraudulent: 0.02286946214735508\n",
      "Probablitity the claim from policy 1196 is fraudulent: 0.01639094203710556\n",
      "Probablitity the claim from policy 1899 is fraudulent: 0.0035273516550660133\n",
      "Probablitity the claim from policy 3411 is fraudulent: 0.006228829268366098\n",
      "Probablitity the claim from policy 3156 is fraudulent: 0.008326106704771519\n",
      "Probablitity the claim from policy 3756 is fraudulent: 0.003878094255924225\n",
      "Probablitity the claim from policy 3173 is fraudulent: 0.09576433897018433\n",
      "Probablitity the claim from policy 4289 is fraudulent: 0.002458328614011407\n",
      "Probablitity the claim from policy 1813 is fraudulent: 0.07359056919813156\n",
      "Probablitity the claim from policy 1637 is fraudulent: 0.04993452876806259\n",
      "Probablitity the claim from policy 3211 is fraudulent: 0.00508071668446064\n",
      "Probablitity the claim from policy 4792 is fraudulent: 0.017895516008138657\n",
      "Probablitity the claim from policy 2993 is fraudulent: 0.004072090610861778\n",
      "Probablitity the claim from policy 4827 is fraudulent: 0.003386843018233776\n",
      "Probablitity the claim from policy 3055 is fraudulent: 0.004245929419994354\n",
      "Probablitity the claim from policy 1552 is fraudulent: 0.002929925685748458\n",
      "Probablitity the claim from policy 325 is fraudulent: 0.004193725995719433\n",
      "Probablitity the claim from policy 2640 is fraudulent: 0.0058144135400652885\n",
      "Probablitity the claim from policy 1420 is fraudulent: 0.0760338306427002\n",
      "Probablitity the claim from policy 3983 is fraudulent: 0.008573297411203384\n",
      "Probablitity the claim from policy 2297 is fraudulent: 0.028080807998776436\n",
      "Probablitity the claim from policy 972 is fraudulent: 0.14078453183174133\n",
      "Probablitity the claim from policy 1209 is fraudulent: 0.018759187310934067\n",
      "Probablitity the claim from policy 4867 is fraudulent: 0.05164305120706558\n",
      "Probablitity the claim from policy 4074 is fraudulent: 0.03555668517947197\n",
      "Probablitity the claim from policy 1847 is fraudulent: 0.11335454136133194\n",
      "Probablitity the claim from policy 142 is fraudulent: 0.037436343729496\n",
      "Probablitity the claim from policy 2232 is fraudulent: 0.023713702335953712\n",
      "Probablitity the claim from policy 2886 is fraudulent: 0.02224995754659176\n",
      "Probablitity the claim from policy 4938 is fraudulent: 0.022342568263411522\n",
      "Probablitity the claim from policy 4273 is fraudulent: 0.027649708092212677\n",
      "Probablitity the claim from policy 3451 is fraudulent: 0.003372438019141555\n",
      "Probablitity the claim from policy 2587 is fraudulent: 0.0026430953294038773\n",
      "Probablitity the claim from policy 4461 is fraudulent: 0.013040095567703247\n",
      "Probablitity the claim from policy 3294 is fraudulent: 0.027389785274863243\n",
      "Probablitity the claim from policy 4491 is fraudulent: 0.02910386398434639\n",
      "Probablitity the claim from policy 3478 is fraudulent: 0.003424739232286811\n",
      "Probablitity the claim from policy 2232 is fraudulent: 0.023713702335953712\n",
      "Probablitity the claim from policy 3946 is fraudulent: 0.0028974958695471287\n",
      "Probablitity the claim from policy 3158 is fraudulent: 0.028670065104961395\n",
      "Probablitity the claim from policy 786 is fraudulent: 0.0038955032359808683\n",
      "Probablitity the claim from policy 485 is fraudulent: 0.01206170953810215\n",
      "Probablitity the claim from policy 401 is fraudulent: 0.0028758938424289227\n",
      "Probablitity the claim from policy 1192 is fraudulent: 0.0037213321775197983\n",
      "Probablitity the claim from policy 1247 is fraudulent: 0.011856745928525925\n",
      "Probablitity the claim from policy 3225 is fraudulent: 0.002458328614011407\n",
      "Probablitity the claim from policy 2188 is fraudulent: 0.018433228135108948\n",
      "Probablitity the claim from policy 4130 is fraudulent: 0.03216509893536568\n",
      "Probablitity the claim from policy 2429 is fraudulent: 0.03851949796080589\n",
      "Probablitity the claim from policy 3627 is fraudulent: 0.004842217080295086\n",
      "Probablitity the claim from policy 3900 is fraudulent: 0.01481026690453291\n",
      "Probablitity the claim from policy 485 is fraudulent: 0.01206170953810215\n"
     ]
    }
   ],
   "source": [
    "import datetime as datetime\n",
    "\n",
    "timer = []\n",
    "MAXRECS = 100\n",
    "\n",
    "\n",
    "def barrage_of_inference():\n",
    "    sample_policy_id = int(test.sample(1)[\"policy_id\"])\n",
    "\n",
    "    temp_fg_name = \"fraud-detect-demo-claims\"\n",
    "\n",
    "    claims_response = featurestore_runtime.get_record(\n",
    "        FeatureGroupName=temp_fg_name, RecordIdentifierValueAsString=str(sample_policy_id)\n",
    "    )\n",
    "\n",
    "    if claims_response.get(\"Record\"):\n",
    "        claims_record = claims_response[\"Record\"]\n",
    "        claims_df = pd.DataFrame(claims_record).set_index(\"FeatureName\")\n",
    "    else:\n",
    "        print(\"No Record returned / Record Key  \\n\")\n",
    "\n",
    "    t0 = datetime.datetime.now()\n",
    "\n",
    "    customers_response = featurestore_runtime.get_record(\n",
    "        FeatureGroupName=customers_fg_name, RecordIdentifierValueAsString=str(sample_policy_id)\n",
    "    )\n",
    "\n",
    "    t1 = datetime.datetime.now()\n",
    "\n",
    "    customer_record = customers_response[\"Record\"]\n",
    "    customer_df = pd.DataFrame(customer_record).set_index(\"FeatureName\")\n",
    "\n",
    "    blended_df = pd.concat([claims_df, customer_df]).loc[col_order].drop(\"fraud\")\n",
    "    data_input = \",\".join(blended_df[\"ValueAsString\"])\n",
    "\n",
    "    results = predictor.predict(data_input, initial_args={\"ContentType\": \"text/csv\"})\n",
    "    prediction = json.loads(results)\n",
    "    # print (f'Probablitity the claim from policy {int(sample_policy_id)} is fraudulent:', prediction)\n",
    "\n",
    "    arr = t1 - t0\n",
    "    minutes, seconds = divmod(arr.total_seconds(), 60)\n",
    "\n",
    "    timer.append(seconds)\n",
    "    # print (prediction, \" done in {} \".format(seconds))\n",
    "\n",
    "    return sample_policy_id, prediction\n",
    "\n",
    "\n",
    "for i in range(MAXRECS):\n",
    "    sample_policy_id, prediction = barrage_of_inference()\n",
    "    print(f\"Probablitity the claim from policy {int(sample_policy_id)} is fraudulent:\", prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.055528,\n",
       " 0.010904,\n",
       " 0.010296,\n",
       " 0.015531,\n",
       " 0.009257,\n",
       " 0.011363,\n",
       " 0.010686,\n",
       " 0.01114,\n",
       " 0.010639,\n",
       " 0.010603,\n",
       " 0.009144,\n",
       " 0.009253,\n",
       " 0.008001,\n",
       " 0.008496,\n",
       " 0.01081,\n",
       " 0.008759,\n",
       " 0.009071,\n",
       " 0.009832,\n",
       " 0.009386,\n",
       " 0.01023,\n",
       " 0.009602,\n",
       " 0.008734,\n",
       " 0.009512,\n",
       " 0.01012,\n",
       " 0.008678,\n",
       " 0.008363,\n",
       " 0.007918,\n",
       " 0.009214,\n",
       " 0.008701,\n",
       " 0.010373,\n",
       " 0.007721,\n",
       " 0.008937,\n",
       " 0.008652,\n",
       " 0.014426,\n",
       " 0.008472,\n",
       " 0.010487,\n",
       " 0.00951,\n",
       " 0.01098,\n",
       " 0.009535,\n",
       " 0.009695,\n",
       " 0.0086,\n",
       " 0.009866,\n",
       " 0.008824,\n",
       " 0.008887,\n",
       " 0.008709,\n",
       " 0.009451,\n",
       " 0.009261,\n",
       " 0.010371,\n",
       " 0.009849,\n",
       " 0.008604,\n",
       " 0.009123,\n",
       " 0.009151,\n",
       " 0.009229,\n",
       " 0.00915,\n",
       " 0.007966,\n",
       " 0.00862,\n",
       " 0.009586,\n",
       " 0.010286,\n",
       " 0.009264,\n",
       " 0.00883,\n",
       " 0.009874,\n",
       " 0.00861,\n",
       " 0.007907,\n",
       " 0.008505,\n",
       " 0.009337,\n",
       " 0.008142,\n",
       " 0.008959,\n",
       " 0.00833,\n",
       " 0.010141,\n",
       " 0.007726,\n",
       " 0.008245,\n",
       " 0.010703,\n",
       " 0.008917,\n",
       " 0.008525,\n",
       " 0.00851,\n",
       " 0.008354,\n",
       " 0.008517,\n",
       " 0.008341,\n",
       " 0.008291,\n",
       " 0.007897,\n",
       " 0.010368,\n",
       " 0.007758,\n",
       " 0.014702,\n",
       " 0.008001,\n",
       " 0.008769,\n",
       " 0.00812,\n",
       " 0.008633,\n",
       " 0.008526,\n",
       " 0.008281,\n",
       " 0.008447,\n",
       " 0.008468,\n",
       " 0.008122,\n",
       " 0.009726,\n",
       " 0.008793,\n",
       " 0.007954,\n",
       " 0.007821,\n",
       " 0.008696,\n",
       " 0.007783,\n",
       " 0.008933,\n",
       " 0.008697]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: 위의 \"timer\"는 첫 번째 통화를 기록한 다음 온라인 피쳐 저장소에 대한 후속 호출을 기록합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p95: 0.011151149999999999, p99: 0.015930970000000204, mean: 0.00972615 for 100 distinct feature store gets\n"
     ]
    }
   ],
   "source": [
    "import statistics\n",
    "import numpy as np\n",
    "\n",
    "statistics.mean(timer)\n",
    "\n",
    "arr = np.array(timer)\n",
    "print(\n",
    "    \"p95: {}, p99: {}, mean: {} for {} distinct feature store gets\".format(\n",
    "        np.percentile(arr, 95), np.percentile(arr, 99), np.mean(arr), MAXRECS\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pull customer data from Customers feature group\n",
    "\n",
    "고객이 즉각적인 승인을 위해 온라인으로 보험 청구를 제출하면, 보험 회사는 온라인 피쳐 저장소에서 고객별 데이터를 가져와 모델 예측을 위한 입력으로 청구 데이터에 추가해야 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "customers_response = featurestore_runtime.get_record(\n",
    "    FeatureGroupName=customers_fg_name, RecordIdentifierValueAsString=str(sample_policy_id)\n",
    ")\n",
    "\n",
    "customer_record = customers_response[\"Record\"]\n",
    "customer_df = pd.DataFrame(customer_record).set_index(\"FeatureName\")\n",
    "\n",
    "\n",
    "claims_response = featurestore_runtime.get_record(\n",
    "    FeatureGroupName=claims_fg_name, RecordIdentifierValueAsString=str(sample_policy_id)\n",
    ")\n",
    "\n",
    "claims_record = claims_response[\"Record\"]\n",
    "claims_df = pd.DataFrame(claims_record).set_index(\"FeatureName\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Format the datapoint\n",
    "\n",
    "데이터 포인트는 모델이 훈련되었을 때, 모든 피쳐가 올바른 순서로 된 정확한 입력 형식과 일치해야 합니다. 이 예에서 `col_order` 변수는 가이드의 앞부분에서 훈련 및 테스트 데이터셋을 만들 때 저장되었습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "blended_df = pd.concat([claims_df, customer_df]).loc[col_order].drop(\"fraud\")\n",
    "data_input = \",\".join(blended_df[\"ValueAsString\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probablitity the claim from policy 485 is fraudulent: 0.01206170953810215\n"
     ]
    }
   ],
   "source": [
    "results = predictor.predict(data_input, initial_args={\"ContentType\": \"text/csv\"})\n",
    "prediction = json.loads(results)\n",
    "print(f\"Probablitity the claim from policy {int(sample_policy_id)} is fraudulent:\", prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "<a id='aud-workflow-pipeline'></a>\n",
    "### Next Notebook: [Create and Run an End-to-End Pipeline to Deploy the Model](./5-pipeline-e2e.ipynb)\n",
    "\n",
    "이제 데이터 과학자로서 머신 러닝 워크플로의 각 단계를 수동으로 실험했으므로, 모델 계보를 통한 투명성 및 추적을 희생하지 않고도 더 빠른 모델 생성 및 배포를 허용하는 특정 단계를 수행할 수 있습니다. 다음 섹션에서는 SageMaker에서 새 모델을 훈련하고 SageMaker에서 모델을 유지한 다음, 모델을 레지스트리에 추가하고 SageMaker 호스팅 엔드 포인트로 배포하는 파이프라인을 생성합니다."
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-2:429704687514:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
